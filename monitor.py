#!/usr/bin/env python3
# ãƒã‚¸ãƒä¸­å¤4ã‚«ãƒ†ã‚´ãƒªå€¤ä¸‹ã’ç›£è¦– - ã‚¹ãƒãƒ›/ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ/PC/ã‚«ãƒ¡ãƒ©ï¼ˆ15åˆ†ã”ã¨ï¼‰

import os
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import sys

CHANNEL_TOKEN = os.getenv('CHANNEL_TOKEN')
NOJIMA_CATEGORIES = {
    "ä¸­å¤ã‚¹ãƒãƒ›": "https://online.nojima.co.jp/category/10006902/",
    "ä¸­å¤ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ": "https://online.nojima.co.jp/category/10006501/",
    "ä¸­å¤PC": "https://online.nojima.co.jp/category/10006301/",
    "ä¸­å¤ã‚«ãƒ¡ãƒ©": "https://online.nojima.co.jp/category/10006201/"
}
PRICE_DB_FILE = "/tmp/nojima_prices.json"
LINE_API_URL = "https://api.line.me/v2/bot/message/broadcast"

if not CHANNEL_TOKEN:
    print("âŒ CHANNEL_TOKEN æœªè¨­å®š")
    sys.exit(1)

def send_line(text):
    headers = {"Authorization": f"Bearer {CHANNEL_TOKEN}", "Content-Type": "application/json"}
    data = {"messages": [{"type": "text", "text": text}]}
    try:
        r = requests.post(LINE_API_URL, headers=headers, json=data, timeout=10)
        print(f"âœ… LINE: {r.status_code}")
        return True
    except:
        return False

def load_db():
    try:
        if os.path.exists(PRICE_DB_FILE):
            with open(PRICE_DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except:
        return {}

def save_db(db):
    try:
        with open(PRICE_DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(db, f, ensure_ascii=False, indent=2)
        print("ğŸ’¾ DBä¿å­˜å®Œäº†")
    except:
        pass

def scrape_category(url, category_name):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.content, 'html.parser')
        products = {}
        
        print(f"ğŸ” {category_name} å–å¾—ä¸­...")
        
        # å•†å“ã‚¢ã‚¤ãƒ†ãƒ å–å¾—ï¼ˆè¤‡æ•°ã‚»ãƒ¬ã‚¯ã‚¿å¯¾å¿œï¼‰
        items = soup.find_all(['div', 'li', 'a'], class_=lambda x: x and any(kw in str(x).lower() for kw in ['product', 'item', 'goods', 'card']))
        
        for item in items[:40]:
            try:
                # å•†å“å
                name_elem = item.find(['h1','h2','h3','h4','.product-name','.item-title','a','span'])
                if name_elem:
                    name = name_elem.get_text(strip=True)[:60]
                else:
                    continue
                
                # ä¾¡æ ¼ï¼ˆÂ¥æŠ½å‡ºï¼‰
                price_text = ''
                price_elems = item.find_all(string=lambda x: x and 'Â¥' in str(x))
                for pe in price_elems:
                    price_text = pe.strip()
                    break
                
                if not price_text:
                    price_span = item.find(['span', 'div', 'p', '.price'], class_=lambda x: x and ('price' in str(x).lower() or 'Â¥' in str(x)))
                    if price_span:
                        price_text = price_span.get_text(strip=True)
                
                price_nums = ''.join(c for c in price_text if c.isdigit())
                if len(price_nums) >= 4:
                    price = int(price_nums)
                    key = f"{category_name}:{name}"
                    products[key] = price
                    print(f"  ğŸ“¦ {name[:30]}: Â¥{price:,}")
                    
            except:
                continue
        
        print(f"  âœ… {category_name}: {len(products)}ä»¶å–å¾—")
        return products
        
    except Exception as e:
        print(f"âŒ {category_name} ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def main():
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S JST')
    print(f"â° ãƒã‚¸ãƒ4ã‚«ãƒ†ã‚´ãƒªç›£è¦–é–‹å§‹: {timestamp}")
    
    # DBèª­ã¿è¾¼ã¿
    price_db = load_db()
    print(f"ğŸ’¾ å‰å›DB: {len(price_db)}ä»¶")
    
    all_drops = []
    
    # 4ã‚«ãƒ†ã‚´ãƒªåŒæ™‚ãƒã‚§ãƒƒã‚¯
    for category_name, url in NOJIMA_CATEGORIES.items():
        current_products = scrape_category(url, category_name)
        
        # å€¤ä¸‹ã’æ¤œçŸ¥
        for key, price in current_products.items():
            if key in price_db and price_db[key] > price:
                drop_amount = price_db[key] - price
                drop_percent = round((drop_amount / price_db[key]) * 100, 1)
                cat_name = key.split(':')[0][:2]
                prod_name = key.split(':', 1)[1]
                all_drops.append({
                    'category': cat_name,
                    'name': prod_name[:35],
                    'old': f"Â¥{price_db[key]:,}",
                    'new': f"Â¥{price:,}",
                    'drop': f"Â¥{drop_amount:,}",
                    'pct': f"{drop_percent}%"
                })
        
        # DBæ›´æ–°
        price_db.update(current_products)
    
    print(f"ğŸ“Š å€¤ä¸‹ã’æ¤œçŸ¥: {len(all_drops)}ä»¶")
    
    # LINEé€šçŸ¥ï¼ˆå€¤ä¸‹ã’æ™‚ã®ã¿ï¼‰
    if all_drops:
        message = f"ğŸ”¥ ã€ãƒã‚¸ãƒå€¤ä¸‹ã’ã€‘{len(all_drops)}ä»¶\nâ° {timestamp}\n\n"
        for drop in sorted(all_drops, key=lambda x: int(x['drop'][1:].replace(',', '')), reverse=True)[:8]:
            message += f"{drop['category']} {drop['name']}\n"
            message += f"   {drop['old']} â†’ {drop['new']}\n"
            message += f"   {drop['drop']} ({drop['pct']})\n\n"
        
        message += "ğŸ”— https://online.nojima.co.jp/category/114/"
        if send_line(message):
            print(f"âœ… å€¤ä¸‹ã’é€šçŸ¥é€ä¿¡: {len(all_drops)}ä»¶")
    else:
        print("ğŸ“Š å€¤ä¸‹ã’ãªã—ï¼ˆæ­£å¸¸ï¼‰")
    
    # DBä¿å­˜
    save_db(price_db)
    print("âœ… ãƒã‚¸ãƒ4ã‚«ãƒ†ã‚´ãƒªç›£è¦–å®Œäº†")

if __name__ == "__main__":
    main()
